{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Data Preparation & Transforms\n",
        "\n",
        "This notebook handles the **data pipeline** for the plant disease classification project:\n",
        "\n",
        "1. **Install** dependencies & configure Kaggle credentials\n",
        "2. **Download** the dataset from Kaggle (YOLO detection format)\n",
        "3. **Organise** images from YOLO format into class-per-folder layout\n",
        "4. **Create subset** by sampling N images per class for train/val/test\n",
        "5. **Define transforms** (CLAHE preprocessing + augmentations)\n",
        "6. **Build datasets & dataloaders** and verify with sample visualisation\n",
        "\n",
        "**Run this notebook first**, then open `02_train_convnextv2.ipynb` for training.\n",
        "\n",
        "**Dataset:** [Plant Disease Detection](https://www.kaggle.com/datasets/ironwolf437/plant-disease-detection-dataset) (7 classes, YOLO format)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q kaggle albumentations pyyaml"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensure CWD is the project root\n",
        "# Works on both Colab and local Jupyter\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def find_project_root():\n",
        "    \"\"\"Find project root by looking for data directory or configs\"\"\"\n",
        "    current = Path(os.getcwd()).resolve()\n",
        "    \n",
        "    # Check if we're already in project root (has data/ or configs/)\n",
        "    if (current / \"data\").is_dir() or (current / \"configs\").is_dir():\n",
        "        return current\n",
        "    \n",
        "    # Check if we're in notebooks/ subdirectory\n",
        "    if current.name == \"notebooks\":\n",
        "        parent = current.parent\n",
        "        if (parent / \"data\").is_dir() or (parent / \"configs\").is_dir():\n",
        "            return parent\n",
        "    \n",
        "    # Search upward from current directory\n",
        "    for parent in current.parents:\n",
        "        if (parent / \"data\").is_dir() or (parent / \"configs\").is_dir():\n",
        "            return parent\n",
        "    \n",
        "    # On Colab, try common repo name\n",
        "    colab_repo = Path(\"/content/plant-disease-classification\")\n",
        "    if colab_repo.exists() and ((colab_repo / \"data\").is_dir() or (colab_repo / \"configs\").is_dir()):\n",
        "        return colab_repo\n",
        "    \n",
        "    return current  # Fallback\n",
        "\n",
        "PROJECT_ROOT = find_project_root()\n",
        "os.chdir(PROJECT_ROOT)\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import yaml\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration\n",
        "\n",
        "All data-related settings in one place. Adjust subset sizes, image size, or CLAHE parameters here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class DataConfig:\n",
        "    \"\"\"Configuration for data preparation and transforms.\"\"\"\n",
        "\n",
        "    # --- Kaggle ---\n",
        "    kaggle_dataset: str = \"ironwolf437/plant-disease-detection-dataset\"\n",
        "\n",
        "    # --- Paths ---\n",
        "    raw_dir: str = \"data/raw\"\n",
        "    organised_dir: str = \"data/organised\"\n",
        "    subset_dir: str = \"data/subset\"\n",
        "\n",
        "    # --- Subset sampling ---\n",
        "    train_per_class: int = 50\n",
        "    val_per_class: int = 15\n",
        "    test_per_class: int = 10\n",
        "\n",
        "    # --- Transforms ---\n",
        "    image_size: int = 224\n",
        "    clahe_clip_limit: float = 2.0\n",
        "    clahe_tile_grid: Tuple[int, int] = (8, 8)\n",
        "\n",
        "    # --- DataLoader ---\n",
        "    batch_size: int = 32\n",
        "    num_workers: int = 2\n",
        "    pin_memory: bool = True\n",
        "\n",
        "    # --- Reproducibility ---\n",
        "    seed: int = 42\n",
        "\n",
        "\n",
        "cfg = DataConfig()\n",
        "random.seed(cfg.seed)\n",
        "np.random.seed(cfg.seed)\n",
        "print(cfg)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataConfig(kaggle_dataset='ironwolf437/plant-disease-detection-dataset', raw_dir='data/raw', organised_dir='data/organised', subset_dir='data/subset', train_per_class=50, val_per_class=15, test_per_class=10, image_size=224, clahe_clip_limit=2.0, clahe_tile_grid=(8, 8), batch_size=32, num_workers=2, pin_memory=True, seed=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DataPreparer\n",
        "\n",
        "Handles the full data pipeline in three steps:\n",
        "\n",
        "| Step | Method | What it does |\n",
        "|------|--------|--------------|\n",
        "| 1 | `download()` | Download & unzip Kaggle dataset (YOLO format) |\n",
        "| 2 | `organise()` | Parse YOLO labels → sort images into class-per-folder layout |\n",
        "| 3 | `create_subset()` | Random sample N images per class per split |\n",
        "\n",
        "Each step is **idempotent** — skips if output already exists. Use `force=True` to redo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
        "\n",
        "\n",
        "class DataPreparer:\n",
        "    \"\"\"Download, organise, and subset the plant disease dataset.\n",
        "\n",
        "    The Kaggle dataset is in YOLO detection format (images/ + labels/).\n",
        "    This class converts it to class-per-folder layout suitable for\n",
        "    PyTorch ImageFolder-style loading.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg: DataConfig):\n",
        "        self.cfg = cfg\n",
        "        self.raw_dir = Path(cfg.raw_dir)\n",
        "        self.organised_dir = Path(cfg.organised_dir)\n",
        "        self.subset_dir = Path(cfg.subset_dir)\n",
        "\n",
        "    # ----- Download -----\n",
        "\n",
        "    def download(self):\n",
        "        \"\"\"Download and unzip the dataset from Kaggle.\"\"\"\n",
        "        self.raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "        zip_path = self.raw_dir / \"plant-disease-detection-dataset.zip\"\n",
        "\n",
        "        if not zip_path.exists() and not any(self.raw_dir.iterdir()):\n",
        "            print(f\"[download] Downloading from Kaggle: {self.cfg.kaggle_dataset}\")\n",
        "            from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "            api = KaggleApi()\n",
        "            api.authenticate()\n",
        "            api.dataset_download_files(\n",
        "                self.cfg.kaggle_dataset, path=str(self.raw_dir), unzip=False\n",
        "            )\n",
        "        else:\n",
        "            print(f\"[download] Already present in {self.raw_dir}\")\n",
        "\n",
        "        if zip_path.exists():\n",
        "            print(\"[download] Unzipping...\")\n",
        "            with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "                zf.extractall(self.raw_dir)\n",
        "            zip_path.unlink()\n",
        "            print(\"[download] Done.\")\n",
        "\n",
        "    # ----- YOLO -> class folders -----\n",
        "\n",
        "    def _parse_class_names(self) -> List[str]:\n",
        "        \"\"\"Read class names from data.yaml in the raw directory.\"\"\"\n",
        "        with open(self.raw_dir / \"data.yaml\") as f:\n",
        "            data_cfg = yaml.safe_load(f)\n",
        "        names = data_cfg[\"names\"]\n",
        "        print(f\"[yolo] {len(names)} classes: {names}\")\n",
        "        return names\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_image_class(label_path: Path) -> Optional[int]:\n",
        "        \"\"\"Read YOLO label file and return the dominant (most frequent) class id.\n",
        "\n",
        "        Each label line: class_id x_center y_center width height\n",
        "        Returns None if the file is missing or empty.\n",
        "        \"\"\"\n",
        "        if not label_path.exists():\n",
        "            return None\n",
        "        class_ids = []\n",
        "        with open(label_path) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    class_ids.append(int(parts[0]))\n",
        "        if not class_ids:\n",
        "            return None\n",
        "        return Counter(class_ids).most_common(1)[0][0]\n",
        "\n",
        "    def organise(self, force: bool = False):\n",
        "        \"\"\"Convert YOLO format to class-per-folder layout.\n",
        "\n",
        "        Maps: raw/{train,valid,test}/images -> organised/{train,val,test}/{class}/\n",
        "        \"\"\"\n",
        "        if not force and self.organised_dir.exists() and any(self.organised_dir.iterdir()):\n",
        "            print(f\"[organise] Already done at {self.organised_dir}, skipping.\")\n",
        "            return\n",
        "\n",
        "        if force and self.organised_dir.exists():\n",
        "            shutil.rmtree(self.organised_dir)\n",
        "\n",
        "        class_names = self._parse_class_names()\n",
        "        split_map = {\"train\": \"train\", \"valid\": \"val\", \"test\": \"test\"}\n",
        "\n",
        "        for raw_split, out_split in split_map.items():\n",
        "            images_dir = self.raw_dir / raw_split / \"images\"\n",
        "            labels_dir = self.raw_dir / raw_split / \"labels\"\n",
        "            if not images_dir.exists():\n",
        "                continue\n",
        "\n",
        "            counts = Counter()\n",
        "            skipped = 0\n",
        "\n",
        "            for img_file in sorted(images_dir.iterdir()):\n",
        "                if img_file.suffix.lower() not in IMAGE_EXTS:\n",
        "                    continue\n",
        "                label_file = labels_dir / (img_file.stem + \".txt\")\n",
        "                class_id = self._get_image_class(label_file)\n",
        "\n",
        "                if class_id is None or class_id >= len(class_names):\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "\n",
        "                class_name = class_names[class_id]\n",
        "                dst = self.organised_dir / out_split / class_name\n",
        "                dst.mkdir(parents=True, exist_ok=True)\n",
        "                shutil.copy2(img_file, dst / img_file.name)\n",
        "                counts[class_name] += 1\n",
        "\n",
        "            total = sum(counts.values())\n",
        "            print(f\"[organise] {out_split}: {total} images ({skipped} skipped)\")\n",
        "            for cls in sorted(counts):\n",
        "                print(f\"    {cls}: {counts[cls]}\")\n",
        "\n",
        "    # ----- Subset -----\n",
        "\n",
        "    def create_subset(self, force: bool = False):\n",
        "        \"\"\"Sample a small subset from the organised dataset.\"\"\"\n",
        "        if (not force\n",
        "            and (self.subset_dir / \"train\").exists()\n",
        "            and any((self.subset_dir / \"train\").iterdir())):\n",
        "            print(f\"[subset] Already exists at {self.subset_dir}, skipping.\")\n",
        "            self._print_summary()\n",
        "            return\n",
        "\n",
        "        if force and self.subset_dir.exists():\n",
        "            shutil.rmtree(self.subset_dir)\n",
        "\n",
        "        rng = random.Random(self.cfg.seed)\n",
        "        limits = {\n",
        "            \"train\": self.cfg.train_per_class,\n",
        "            \"val\": self.cfg.val_per_class,\n",
        "            \"test\": self.cfg.test_per_class,\n",
        "        }\n",
        "\n",
        "        for split, n_per_class in limits.items():\n",
        "            split_src = self.organised_dir / split\n",
        "            if not split_src.exists():\n",
        "                continue\n",
        "\n",
        "            classes = sorted(\n",
        "                d.name for d in split_src.iterdir()\n",
        "                if d.is_dir() and not d.name.startswith(\".\")\n",
        "            )\n",
        "            for cls in classes:\n",
        "                cls_dir = split_src / cls\n",
        "                images = sorted(\n",
        "                    f.name for f in cls_dir.iterdir()\n",
        "                    if f.is_file() and f.suffix.lower() in IMAGE_EXTS\n",
        "                )\n",
        "                sampled = images if len(images) <= n_per_class else rng.sample(images, n_per_class)\n",
        "\n",
        "                dst = self.subset_dir / split / cls\n",
        "                dst.mkdir(parents=True, exist_ok=True)\n",
        "                for img_name in sampled:\n",
        "                    shutil.copy2(cls_dir / img_name, dst / img_name)\n",
        "\n",
        "        self._print_summary()\n",
        "\n",
        "    def _print_summary(self):\n",
        "        \"\"\"Print image counts per split.\"\"\"\n",
        "        print(f\"\\n[subset] Summary:\")\n",
        "        for split in [\"train\", \"val\", \"test\"]:\n",
        "            split_path = self.subset_dir / split\n",
        "            if not split_path.exists():\n",
        "                print(f\"  {split}: (not found)\")\n",
        "                continue\n",
        "            n_images = sum(\n",
        "                len(list((split_path / c).iterdir()))\n",
        "                for c in os.listdir(split_path)\n",
        "                if (split_path / c).is_dir()\n",
        "            )\n",
        "            n_classes = len([\n",
        "                c for c in os.listdir(split_path)\n",
        "                if (split_path / c).is_dir()\n",
        "            ])\n",
        "            print(f\"  {split}: {n_images} images across {n_classes} classes\")\n",
        "\n",
        "    def run(self, force: bool = False):\n",
        "        \"\"\"Execute full pipeline: download -> organise -> subset.\"\"\"\n",
        "        self.download()\n",
        "        self.organise(force=force)\n",
        "        self.create_subset(force=force)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_preparer = DataPreparer(cfg)\n",
        "data_preparer.run()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[download] Downloading from Kaggle: ironwolf437/plant-disease-detection-dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2675567169.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_preparer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPreparer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_preparer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2374724738.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;34m\"\"\"Execute full pipeline: download -> organise -> subset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morganise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2374724738.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mzip_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[download] Downloading from Kaggle: {self.cfg.kaggle_dataset}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaggle_api_extended\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kaggle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         raise IOError('Could not find {}. Make sure it\\'s located in'\n\u001b[0m\u001b[1;32m    435\u001b[0m                       \u001b[0;34m' {}. Or use the environment method. See setup'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                       \u001b[0;34m' instructions at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Dataset & Transforms\n",
        "\n",
        "**CLAHE** (Contrast Limited Adaptive Histogram Equalization) is applied as a **deterministic preprocessing step** (p=1.0) in both train and val/test to handle greenhouse fog/LED lighting.\n",
        "\n",
        "| Pipeline | Transforms |\n",
        "|----------|------------|\n",
        "| **Train** | Resize -> CLAHE -> HFlip, VFlip, Rotate90, ShiftScaleRotate, ColorJitter, GaussNoise, GaussianBlur -> Normalize -> ToTensor |\n",
        "| **Val/Test** | Resize -> CLAHE -> Normalize -> ToTensor |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "class PlantDiseaseDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for plant disease images in class-per-folder layout.\n",
        "\n",
        "    Expects:\n",
        "        root_dir/\n",
        "            class_a/\n",
        "                img1.jpg\n",
        "            class_b/\n",
        "                img2.jpg\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir: str, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples: List[Tuple[str, int]] = []\n",
        "        self.classes: List[str] = []\n",
        "        self.class_to_idx: Dict[str, int] = {}\n",
        "        self._scan()\n",
        "\n",
        "    def _scan(self):\n",
        "        self.classes = sorted(\n",
        "            d for d in os.listdir(self.root_dir)\n",
        "            if os.path.isdir(os.path.join(self.root_dir, d))\n",
        "        )\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.root_dir, cls)\n",
        "            for fname in sorted(os.listdir(cls_dir)):\n",
        "                ext = os.path.splitext(fname)[1].lower()\n",
        "                if ext in IMAGE_EXTS:\n",
        "                    self.samples.append(\n",
        "                        (os.path.join(cls_dir, fname), self.class_to_idx[cls])\n",
        "                    )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class TransformFactory:\n",
        "    \"\"\"Build Albumentations pipelines for train and val/test.\"\"\"\n",
        "\n",
        "    def __init__(self, cfg: DataConfig):\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def train(self) -> A.Compose:\n",
        "        \"\"\"Training pipeline: CLAHE + augmentations + normalise.\"\"\"\n",
        "        return A.Compose([\n",
        "            A.Resize(self.cfg.image_size, self.cfg.image_size),\n",
        "            A.CLAHE(\n",
        "                clip_limit=self.cfg.clahe_clip_limit,\n",
        "                tile_grid_size=self.cfg.clahe_tile_grid,\n",
        "                p=1.0,\n",
        "            ),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.5\n",
        "            ),\n",
        "            A.ColorJitter(\n",
        "                brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5\n",
        "            ),\n",
        "            A.GaussNoise(p=0.3),\n",
        "            A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "    def val(self) -> A.Compose:\n",
        "        \"\"\"Val/test pipeline: CLAHE + normalise (no augmentation).\"\"\"\n",
        "        return A.Compose([\n",
        "            A.Resize(self.cfg.image_size, self.cfg.image_size),\n",
        "            A.CLAHE(\n",
        "                clip_limit=self.cfg.clahe_clip_limit,\n",
        "                tile_grid_size=self.cfg.clahe_tile_grid,\n",
        "                p=1.0,\n",
        "            ),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "            ToTensorV2(),\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tf = TransformFactory(cfg)\n",
        "\n",
        "train_dataset = PlantDiseaseDataset(os.path.join(cfg.subset_dir, \"train\"), transform=tf.train())\n",
        "val_dataset   = PlantDiseaseDataset(os.path.join(cfg.subset_dir, \"val\"),   transform=tf.val())\n",
        "test_dataset  = PlantDiseaseDataset(os.path.join(cfg.subset_dir, \"test\"),  transform=tf.val())\n",
        "\n",
        "CLASS_NAMES = train_dataset.classes\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "print(f\"Classes ({NUM_CLASSES}): {CLASS_NAMES}\")\n",
        "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=cfg.batch_size, shuffle=True,\n",
        "    num_workers=cfg.num_workers, pin_memory=cfg.pin_memory,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=cfg.batch_size, shuffle=False,\n",
        "    num_workers=cfg.num_workers, pin_memory=cfg.pin_memory,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=cfg.batch_size, shuffle=False,\n",
        "    num_workers=cfg.num_workers, pin_memory=cfg.pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Verify: Sample Images\n",
        "\n",
        "Visualise a batch of training images to confirm transforms are working correctly.  \n",
        "Images are de-normalised back to [0, 1] for display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_batch(dataset, class_names, n=8):\n",
        "    \"\"\"Display n random samples from the dataset.\"\"\"\n",
        "    mean = np.array(IMAGENET_MEAN)\n",
        "    std = np.array(IMAGENET_STD)\n",
        "\n",
        "    indices = random.sample(range(len(dataset)), min(n, len(dataset)))\n",
        "    cols = min(4, n)\n",
        "    rows = (n + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
        "    if rows == 1:\n",
        "        axes = [axes] if cols == 1 else list(axes)\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for ax_idx, data_idx in enumerate(indices):\n",
        "        img_tensor, label = dataset[data_idx]\n",
        "        img_np = img_tensor.permute(1, 2, 0).numpy()\n",
        "        img_np = img_np * std + mean\n",
        "        img_np = np.clip(img_np, 0, 1)\n",
        "\n",
        "        axes[ax_idx].imshow(img_np)\n",
        "        axes[ax_idx].set_title(class_names[label], fontsize=10)\n",
        "        axes[ax_idx].axis(\"off\")\n",
        "\n",
        "    for ax_idx in range(len(indices), len(axes)):\n",
        "        axes[ax_idx].axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\"Sample Training Images (after transforms)\", fontsize=13)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_batch(train_dataset, CLASS_NAMES, n=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_class_distribution(dataset, class_names, title=\"Class Distribution\"):\n",
        "    \"\"\"Bar chart of samples per class.\"\"\"\n",
        "    counts = Counter(label for _, label in dataset.samples)\n",
        "    names = [class_names[i] for i in range(len(class_names))]\n",
        "    values = [counts.get(i, 0) for i in range(len(class_names))]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    bars = ax.bar(names, values, color=\"steelblue\")\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    ax.set_title(title)\n",
        "    ax.bar_label(bars)\n",
        "    plt.xticks(rotation=30, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_class_distribution(train_dataset, CLASS_NAMES, \"Train Subset - Class Distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done\n",
        "\n",
        "Data is ready. Outputs:\n",
        "- `data/organised/{train,val,test}/{class}/` — full dataset in class-folder layout\n",
        "- `data/subset/{train,val,test}/{class}/` — small subset for quick training\n",
        "\n",
        "**Next step:** Open `02_train_convnextv2.ipynb` to train the model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}